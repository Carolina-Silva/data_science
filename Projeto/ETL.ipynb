{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f03628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa667283",
   "metadata": {},
   "source": [
    "ftp://ftp.datasus.gov.br/dissemin/publicos/SIM/CID10/DORES\n",
    "\n",
    "\n",
    "DOSP2023.dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a28a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações do FTP ---\n",
    "FTP_HOST = \"ftp.datasus.gov.br\"  # Substitua pelo seu host\n",
    "FTP_DIR = \"/dissemin/publicos/SIM/CID10/DORES/\" # O diretório onde o arquivo está\n",
    "FILENAME_TO_DOWNLOAD = \"DOSP2023.dbc\"         # O arquivo que queremos baixar\n",
    "DOWNLOAD_DIR = \"dados/\" # Pasta local para salvar os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b87acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "local_filepath = os.path.join(DOWNLOAD_DIR, FILENAME_TO_DOWNLOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbbf121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login anônimo no ftp.datasus.gov.br realizado com sucesso.\n",
      "Navegado para o diretório: /dissemin/publicos/SIM/CID10/DORES/\n",
      "Baixando DOSP2023.dbc para dados/DOSP2023.dbc...\n",
      "Download de DOSP2023.dbc concluído.\n",
      "Conexão FTP fechada.\n"
     ]
    }
   ],
   "source": [
    "# --- Conexão ---\n",
    "try:\n",
    "    ftp = ftplib.FTP(FTP_HOST)\n",
    "    ftp.login() # Login anônimo\n",
    "    print(f\"Login anônimo no {FTP_HOST} realizado com sucesso.\")\n",
    "    \n",
    "    # --- MUDANÇA NA LÓGICA ---\n",
    "    \n",
    "    # 1. Entra no diretório CORRETO\n",
    "    ftp.cwd(FTP_DIR)\n",
    "    print(f\"Navegado para o diretório: {FTP_DIR}\")\n",
    "\n",
    "    # 2. Não precisamos listar arquivos (ftp.nlst())\n",
    "    # 3. Não precisamos de loop (for ...:)\n",
    "    \n",
    "    # 4. Baixa o arquivo específico diretamente\n",
    "    print(f\"Baixando {FILENAME_TO_DOWNLOAD} para {local_filepath}...\")\n",
    "    \n",
    "    # Abre o arquivo local em modo 'wb' (write binary)\n",
    "    with open(local_filepath, 'wb') as local_file:\n",
    "        # Comando para baixar o arquivo\n",
    "        ftp.retrbinary(f'RETR {FILENAME_TO_DOWNLOAD}', local_file.write)\n",
    "    \n",
    "    print(f\"Download de {FILENAME_TO_DOWNLOAD} concluído.\")\n",
    "\n",
    "    # Fecha a conexão\n",
    "    ftp.quit()\n",
    "    print(\"Conexão FTP fechada.\")\n",
    "\n",
    "except ftplib.all_errors as e:\n",
    "    print(f\"Erro no FTP: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3945756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pysus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e95229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: __file__ não definido. Usando diretório atual (cwd) como base.\n",
      "Iniciando conversão de DOSP2023.dbc...\n",
      "Arquivo de entrada: /home/carolina/lgcm/projects/data_science/Projeto/dados/DOSP2023.dbc\n",
      "Arquivo de saída: /home/carolina/lgcm/projects/data_science/Projeto/dados_processados/DOSP2023.csv\n",
      "Lendo e descompactando /home/carolina/lgcm/projects/data_science/Projeto/dados/DOSP2023.dbc...\n",
      "Arquivo lido com sucesso. Total de 334303 linhas.\n",
      "\n",
      "Primeiras 5 linhas dos dados:\n",
      "  ORIGEM TIPOBITO   DTOBITO HORAOBITO NATURAL CODMUNNATU    DTNASC IDADE SEXO  \\\n",
      "0      1        2  01012023      0720     835     351492  08011945   477    2   \n",
      "1      1        2  01012023      2300     822     220010  02091979   443    1   \n",
      "2      1        2  01012023      2150     835     350400  17122022   215    1   \n",
      "3      1        2  01072023      0815     841     410050  07121989   433    1   \n",
      "4      1        2  01072023      1935     825     251660  06021942   481    2   \n",
      "\n",
      "  RACACOR  ...  FONTES TPRESGINFO TPNIVELINV NUDIASINF  DTCADINF MORTEPARTO  \\\n",
      "0       1  ...                                                                \n",
      "1       1  ...                                                                \n",
      "2       1  ...  SXXXXX                                  02022023          3   \n",
      "3       1  ...                                                                \n",
      "4       1  ...                                                                \n",
      "\n",
      "  DTCONCASO FONTESINF ALTCAUSA CONTADOR  \n",
      "0                                     2  \n",
      "1                                     3  \n",
      "2  02022023                  2        5  \n",
      "3                                     6  \n",
      "4                                     7  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "\n",
      "Salvando como CSV em /home/carolina/lgcm/projects/data_science/Projeto/dados_processados/DOSP2023.csv...\n",
      "Conversão para CSV concluída.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Importa a função de leitura do pysus\n",
    "from pysus.utilities.readdbc import read_dbc\n",
    "\n",
    "# --- Configuração dos Caminhos ---\n",
    "\n",
    "# 1. Pega o caminho da pasta onde este script .py está\n",
    "# (Use 'os.path.abspath(__file__)' se estiver executando como script)\n",
    "# (Use 'os.getcwd()' se estiver em um notebook)\n",
    "try:\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # __file__ não é definido em ambientes interativos (como notebooks)\n",
    "    # Nesses casos, usamos o diretório de trabalho atual\n",
    "    script_dir = os.getcwd()\n",
    "    print(\"Aviso: __file__ não definido. Usando diretório atual (cwd) como base.\")\n",
    "\n",
    "\n",
    "# 2. Define os diretórios com base na pasta do script\n",
    "# O 'downloader_v2.py' salvou os dados em 'dados/'\n",
    "DADOS_BRUTOS_DIR = os.path.join(script_dir, \"dados\")\n",
    "# Onde salvaremos os CSVs processados\n",
    "DADOS_PROCESSADOS_DIR = os.path.join(script_dir, \"dados_processados\")\n",
    "\n",
    "# 3. Garante que a pasta de saída exista\n",
    "os.makedirs(DADOS_PROCESSADOS_DIR, exist_ok=True)\n",
    "\n",
    "# 4. Define os nomes dos arquivos\n",
    "filename_dbc = \"DOSP2023.dbc\" # O arquivo que você baixou\n",
    "filename_csv = \"DOSP2023.csv\" # O nome do arquivo final\n",
    "\n",
    "# 5. Define os caminhos completos\n",
    "path_dbc = os.path.join(DADOS_BRUTOS_DIR, filename_dbc)\n",
    "path_csv = os.path.join(DADOS_PROCESSADOS_DIR, filename_csv)\n",
    "\n",
    "print(f\"Iniciando conversão de {filename_dbc}...\")\n",
    "print(f\"Arquivo de entrada: {path_dbc}\")\n",
    "print(f\"Arquivo de saída: {path_csv}\")\n",
    "\n",
    "try:\n",
    "    # --- PASSO 1 e 2 (Combinados): Ler o .dbc direto para o Pandas ---\n",
    "    \n",
    "    # A função read_dbc faz tudo: descompacta e lê.\n",
    "    # Usamos 'iso-8859-1' (latin1) porque é o encoding padrão do DATASUS.\n",
    "    print(f\"Lendo e descompactando {path_dbc}...\")\n",
    "    df = read_dbc(path_dbc, encoding='iso-8859-1')\n",
    "    \n",
    "    print(f\"Arquivo lido com sucesso. Total de {len(df)} linhas.\")\n",
    "    print(\"\\nPrimeiras 5 linhas dos dados:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # --- PASSO 3: Salvar como .csv ---\n",
    "    print(f\"\\nSalvando como CSV em {path_csv}...\")\n",
    "    # Usamos index=False para não salvar o índice do Pandas no CSV\n",
    "    # Usamos encoding 'utf-8' para garantir compatibilidade\n",
    "    df.to_csv(path_csv, index=False, encoding='utf-8')\n",
    "    print(\"Conversão para CSV concluída.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo de entrada não foi encontrado em {path_dbc}\")\n",
    "    print(\"Verifique se o script 'downloader_v2.py' foi executado com sucesso e o arquivo está na pasta 'dados'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564ffae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Projeto/dados_processados/DOSP2023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbf72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Carregando Amostra (1000 linhas) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGEM</th>\n",
       "      <th>TIPOBITO</th>\n",
       "      <th>DTOBITO</th>\n",
       "      <th>HORAOBITO</th>\n",
       "      <th>NATURAL</th>\n",
       "      <th>CODMUNNATU</th>\n",
       "      <th>DTNASC</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>RACACOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FONTES</th>\n",
       "      <th>TPRESGINFO</th>\n",
       "      <th>TPNIVELINV</th>\n",
       "      <th>NUDIASINF</th>\n",
       "      <th>DTCADINF</th>\n",
       "      <th>MORTEPARTO</th>\n",
       "      <th>DTCONCASO</th>\n",
       "      <th>FONTESINF</th>\n",
       "      <th>ALTCAUSA</th>\n",
       "      <th>CONTADOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>720.0</td>\n",
       "      <td>835</td>\n",
       "      <td>351492</td>\n",
       "      <td>8011945</td>\n",
       "      <td>477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>822</td>\n",
       "      <td>220010</td>\n",
       "      <td>2091979</td>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>835</td>\n",
       "      <td>350400</td>\n",
       "      <td>17122022</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>SXXXXX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1072023</td>\n",
       "      <td>815.0</td>\n",
       "      <td>841</td>\n",
       "      <td>410050</td>\n",
       "      <td>7121989</td>\n",
       "      <td>433</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1072023</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>825</td>\n",
       "      <td>251660</td>\n",
       "      <td>6021942</td>\n",
       "      <td>481</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>835</td>\n",
       "      <td>355280</td>\n",
       "      <td>6062022</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>SXXXXX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11012023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>725.0</td>\n",
       "      <td>835</td>\n",
       "      <td>355030</td>\n",
       "      <td>11011962</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>510.0</td>\n",
       "      <td>823</td>\n",
       "      <td>230450</td>\n",
       "      <td>17071943</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>835</td>\n",
       "      <td>350480</td>\n",
       "      <td>27031953</td>\n",
       "      <td>469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1012023</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>835</td>\n",
       "      <td>355260</td>\n",
       "      <td>19041939</td>\n",
       "      <td>483</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ORIGEM  TIPOBITO  DTOBITO  HORAOBITO  NATURAL  CODMUNNATU    DTNASC  \\\n",
       "0        1         2  1012023      720.0      835      351492   8011945   \n",
       "1        1         2  1012023     2300.0      822      220010   2091979   \n",
       "2        1         2  1012023     2150.0      835      350400  17122022   \n",
       "3        1         2  1072023      815.0      841      410050   7121989   \n",
       "4        1         2  1072023     1935.0      825      251660   6021942   \n",
       "..     ...       ...      ...        ...      ...         ...       ...   \n",
       "95       1         2  1012023     1502.0      835      355280   6062022   \n",
       "96       1         2  1012023      725.0      835      355030  11011962   \n",
       "97       1         2  1012023      510.0      823      230450  17071943   \n",
       "98       1         2  1012023     1340.0      835      350480  27031953   \n",
       "99       1         2  1012023     2100.0      835      355260  19041939   \n",
       "\n",
       "    IDADE  SEXO  RACACOR  ...  FONTES  TPRESGINFO  TPNIVELINV  NUDIASINF  \\\n",
       "0     477     2        1  ...     NaN         NaN         NaN        NaN   \n",
       "1     443     1        1  ...     NaN         NaN         NaN        NaN   \n",
       "2     215     1        1  ...  SXXXXX         NaN         NaN        NaN   \n",
       "3     433     1        1  ...     NaN         NaN         NaN        NaN   \n",
       "4     481     2        1  ...     NaN         NaN         NaN        NaN   \n",
       "..    ...   ...      ...  ...     ...         ...         ...        ...   \n",
       "95    306     1        4  ...  SXXXXX         NaN         NaN        NaN   \n",
       "96    460     1        1  ...     NaN         NaN         NaN        NaN   \n",
       "97    479     2        1  ...     NaN         NaN         NaN        NaN   \n",
       "98    469     1        1  ...     NaN         NaN         NaN        NaN   \n",
       "99    483     2        1  ...     NaN         NaN         NaN        NaN   \n",
       "\n",
       "      DTCADINF  MORTEPARTO  DTCONCASO  FONTESINF  ALTCAUSA  CONTADOR  \n",
       "0          NaN         NaN        NaN        NaN       NaN         2  \n",
       "1          NaN         NaN        NaN        NaN       NaN         3  \n",
       "2    2022023.0         3.0  2022023.0        NaN       2.0         5  \n",
       "3          NaN         NaN        NaN        NaN       NaN         6  \n",
       "4          NaN         NaN        NaN        NaN       NaN         7  \n",
       "..         ...         ...        ...        ...       ...       ...  \n",
       "95  11012023.0         3.0        NaN        NaN       1.0       285  \n",
       "96         NaN         NaN        NaN        NaN       NaN       286  \n",
       "97         NaN         NaN        NaN        NaN       NaN       287  \n",
       "98         NaN         NaN        NaN        NaN       NaN       288  \n",
       "99         NaN         NaN        NaN        NaN       NaN       289  \n",
       "\n",
       "[100 rows x 87 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Carregando Amostra (1000 linhas) ---\")\n",
    "df_amostra = pd.read_csv(csv_path, nrows=100)\n",
    "df_amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b9074e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORIGEM', 'TIPOBITO', 'DTOBITO', 'HORAOBITO', 'NATURAL', 'CODMUNNATU',\n",
       "       'DTNASC', 'IDADE', 'SEXO', 'RACACOR', 'ESTCIV', 'ESC', 'ESC2010',\n",
       "       'SERIESCFAL', 'OCUP', 'CODMUNRES', 'LOCOCOR', 'CODESTAB', 'ESTABDESCR',\n",
       "       'CODMUNOCOR', 'IDADEMAE', 'ESCMAE', 'ESCMAE2010', 'SERIESCMAE',\n",
       "       'OCUPMAE', 'QTDFILVIVO', 'QTDFILMORT', 'GRAVIDEZ', 'SEMAGESTAC',\n",
       "       'GESTACAO', 'PARTO', 'OBITOPARTO', 'PESO', 'TPMORTEOCO', 'OBITOGRAV',\n",
       "       'OBITOPUERP', 'ASSISTMED', 'EXAME', 'CIRURGIA', 'NECROPSIA', 'LINHAA',\n",
       "       'LINHAB', 'LINHAC', 'LINHAD', 'LINHAII', 'CAUSABAS', 'CB_PRE',\n",
       "       'COMUNSVOIM', 'DTATESTADO', 'CIRCOBITO', 'ACIDTRAB', 'FONTE',\n",
       "       'NUMEROLOTE', 'TPPOS', 'DTINVESTIG', 'CAUSABAS_O', 'DTCADASTRO',\n",
       "       'ATESTANTE', 'STCODIFICA', 'CODIFICADO', 'VERSAOSIST', 'VERSAOSCB',\n",
       "       'FONTEINV', 'DTRECEBIM', 'ATESTADO', 'DTRECORIGA', 'CAUSAMAT',\n",
       "       'ESCMAEAGR1', 'ESCFALAGR1', 'STDOEPIDEM', 'STDONOVA', 'DIFDATA',\n",
       "       'NUDIASOBCO', 'NUDIASOBIN', 'DTCADINV', 'TPOBITOCOR', 'DTCONINV',\n",
       "       'FONTES', 'TPRESGINFO', 'TPNIVELINV', 'NUDIASINF', 'DTCADINF',\n",
       "       'MORTEPARTO', 'DTCONCASO', 'FONTESINF', 'ALTCAUSA', 'CONTADOR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amostra.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collina-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
