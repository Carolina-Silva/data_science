{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f03628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa667283",
   "metadata": {},
   "source": [
    "ftp://ftp.datasus.gov.br/dissemin/publicos/SIM/CID10/DORES\n",
    "\n",
    "\n",
    "DOSP2023.dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a28a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações do FTP ---\n",
    "FTP_HOST = \"ftp.datasus.gov.br\"  # Substitua pelo seu host\n",
    "FTP_DIR = \"/dissemin/publicos/SIM/CID10/DORES/\" # O diretório onde o arquivo está\n",
    "FILENAME_TO_DOWNLOAD = \"DOSP2023.dbc\"         # O arquivo que queremos baixar\n",
    "DOWNLOAD_DIR = \"dados/\" # Pasta local para salvar os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b87acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "local_filepath = os.path.join(DOWNLOAD_DIR, FILENAME_TO_DOWNLOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbbf121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login anônimo no ftp.datasus.gov.br realizado com sucesso.\n",
      "Navegado para o diretório: /dissemin/publicos/SIM/CID10/DORES/\n",
      "Baixando DOSP2023.dbc para dados/DOSP2023.dbc...\n",
      "Download de DOSP2023.dbc concluído.\n",
      "Conexão FTP fechada.\n"
     ]
    }
   ],
   "source": [
    "# --- Conexão ---\n",
    "try:\n",
    "    ftp = ftplib.FTP(FTP_HOST)\n",
    "    ftp.login() # Login anônimo\n",
    "    print(f\"Login anônimo no {FTP_HOST} realizado com sucesso.\")\n",
    "    \n",
    "    # --- MUDANÇA NA LÓGICA ---\n",
    "    \n",
    "    # 1. Entra no diretório CORRETO\n",
    "    ftp.cwd(FTP_DIR)\n",
    "    print(f\"Navegado para o diretório: {FTP_DIR}\")\n",
    "\n",
    "    # 2. Não precisamos listar arquivos (ftp.nlst())\n",
    "    # 3. Não precisamos de loop (for ...:)\n",
    "    \n",
    "    # 4. Baixa o arquivo específico diretamente\n",
    "    print(f\"Baixando {FILENAME_TO_DOWNLOAD} para {local_filepath}...\")\n",
    "    \n",
    "    # Abre o arquivo local em modo 'wb' (write binary)\n",
    "    with open(local_filepath, 'wb') as local_file:\n",
    "        # Comando para baixar o arquivo\n",
    "        ftp.retrbinary(f'RETR {FILENAME_TO_DOWNLOAD}', local_file.write)\n",
    "    \n",
    "    print(f\"Download de {FILENAME_TO_DOWNLOAD} concluído.\")\n",
    "\n",
    "    # Fecha a conexão\n",
    "    ftp.quit()\n",
    "    print(\"Conexão FTP fechada.\")\n",
    "\n",
    "except ftplib.all_errors as e:\n",
    "    print(f\"Erro no FTP: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3945756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pysus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e95229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: __file__ não definido. Usando diretório atual (cwd) como base.\n",
      "Iniciando conversão de DOSP2023.dbc...\n",
      "Arquivo de entrada: /home/carolina/lgcm/projects/data_science/Projeto/dados/DOSP2023.dbc\n",
      "Arquivo de saída: /home/carolina/lgcm/projects/data_science/Projeto/dados_processados/DOSP2023.csv\n",
      "Lendo e descompactando /home/carolina/lgcm/projects/data_science/Projeto/dados/DOSP2023.dbc...\n",
      "Arquivo lido com sucesso. Total de 334303 linhas.\n",
      "\n",
      "Primeiras 5 linhas dos dados:\n",
      "  ORIGEM TIPOBITO   DTOBITO HORAOBITO NATURAL CODMUNNATU    DTNASC IDADE SEXO  \\\n",
      "0      1        2  01012023      0720     835     351492  08011945   477    2   \n",
      "1      1        2  01012023      2300     822     220010  02091979   443    1   \n",
      "2      1        2  01012023      2150     835     350400  17122022   215    1   \n",
      "3      1        2  01072023      0815     841     410050  07121989   433    1   \n",
      "4      1        2  01072023      1935     825     251660  06021942   481    2   \n",
      "\n",
      "  RACACOR  ...  FONTES TPRESGINFO TPNIVELINV NUDIASINF  DTCADINF MORTEPARTO  \\\n",
      "0       1  ...                                                                \n",
      "1       1  ...                                                                \n",
      "2       1  ...  SXXXXX                                  02022023          3   \n",
      "3       1  ...                                                                \n",
      "4       1  ...                                                                \n",
      "\n",
      "  DTCONCASO FONTESINF ALTCAUSA CONTADOR  \n",
      "0                                     2  \n",
      "1                                     3  \n",
      "2  02022023                  2        5  \n",
      "3                                     6  \n",
      "4                                     7  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "\n",
      "Salvando como CSV em /home/carolina/lgcm/projects/data_science/Projeto/dados_processados/DOSP2023.csv...\n",
      "Conversão para CSV concluída.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Importa a função de leitura do pysus\n",
    "from pysus.utilities.readdbc import read_dbc\n",
    "\n",
    "# --- Configuração dos Caminhos ---\n",
    "\n",
    "# 1. Pega o caminho da pasta onde este script .py está\n",
    "# (Use 'os.path.abspath(__file__)' se estiver executando como script)\n",
    "# (Use 'os.getcwd()' se estiver em um notebook)\n",
    "try:\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # __file__ não é definido em ambientes interativos (como notebooks)\n",
    "    # Nesses casos, usamos o diretório de trabalho atual\n",
    "    script_dir = os.getcwd()\n",
    "    print(\"Aviso: __file__ não definido. Usando diretório atual (cwd) como base.\")\n",
    "\n",
    "\n",
    "# 2. Define os diretórios com base na pasta do script\n",
    "# O 'downloader_v2.py' salvou os dados em 'dados/'\n",
    "DADOS_BRUTOS_DIR = os.path.join(script_dir, \"dados\")\n",
    "# Onde salvaremos os CSVs processados\n",
    "DADOS_PROCESSADOS_DIR = os.path.join(script_dir, \"dados_processados\")\n",
    "\n",
    "# 3. Garante que a pasta de saída exista\n",
    "os.makedirs(DADOS_PROCESSADOS_DIR, exist_ok=True)\n",
    "\n",
    "# 4. Define os nomes dos arquivos\n",
    "filename_dbc = \"DOSP2023.dbc\" # O arquivo que você baixou\n",
    "filename_csv = \"DOSP2023.csv\" # O nome do arquivo final\n",
    "\n",
    "# 5. Define os caminhos completos\n",
    "path_dbc = os.path.join(DADOS_BRUTOS_DIR, filename_dbc)\n",
    "path_csv = os.path.join(DADOS_PROCESSADOS_DIR, filename_csv)\n",
    "\n",
    "print(f\"Iniciando conversão de {filename_dbc}...\")\n",
    "print(f\"Arquivo de entrada: {path_dbc}\")\n",
    "print(f\"Arquivo de saída: {path_csv}\")\n",
    "\n",
    "try:\n",
    "    # --- PASSO 1 e 2 (Combinados): Ler o .dbc direto para o Pandas ---\n",
    "    \n",
    "    # A função read_dbc faz tudo: descompacta e lê.\n",
    "    # Usamos 'iso-8859-1' (latin1) porque é o encoding padrão do DATASUS.\n",
    "    print(f\"Lendo e descompactando {path_dbc}...\")\n",
    "    df = read_dbc(path_dbc, encoding='iso-8859-1')\n",
    "    \n",
    "    print(f\"Arquivo lido com sucesso. Total de {len(df)} linhas.\")\n",
    "    print(\"\\nPrimeiras 5 linhas dos dados:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # --- PASSO 3: Salvar como .csv ---\n",
    "    print(f\"\\nSalvando como CSV em {path_csv}...\")\n",
    "    # Usamos index=False para não salvar o índice do Pandas no CSV\n",
    "    # Usamos encoding 'utf-8' para garantir compatibilidade\n",
    "    df.to_csv(path_csv, index=False, encoding='utf-8')\n",
    "    print(\"Conversão para CSV concluída.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo de entrada não foi encontrado em {path_dbc}\")\n",
    "    print(\"Verifique se o script 'downloader_v2.py' foi executado com sucesso e o arquivo está na pasta 'dados'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collina-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
